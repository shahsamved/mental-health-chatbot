{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da17c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa1d3ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           What does it mean to have a mental illness?\n",
       "1                       Who does mental illness affect?\n",
       "2                           What causes mental illness?\n",
       "3     What are some of the warning signs of mental i...\n",
       "4               Can people with mental illness recover?\n",
       "                            ...                        \n",
       "93              How do I know if I'm drinking too much?\n",
       "94    If cannabis is dangerous, why are we legalizin...\n",
       "95         How can I convince my kids not to use drugs?\n",
       "96    What is the legal status (and evidence) of CBD...\n",
       "97                      What is the evidence on vaping?\n",
       "Name: Questions, Length: 98, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Load your CSV dataset\n",
    "df = pd.read_csv(\"Mental_Health_FAQ.csv\")\n",
    "df['Questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c30f0154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahs\\anaconda3\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='201' max='201' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [201/201 27:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=201, training_loss=2.705742831253887, metrics={'train_runtime': 1668.0151, 'train_samples_per_second': 0.477, 'train_steps_per_second': 0.121, 'total_flos': 51931791360000.0, 'train_loss': 2.705742831253887, 'epoch': 3.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Combine question and answer for training\n",
    "df['input_text'] = df['Questions'] + \" \" + df['Answers']\n",
    "\n",
    "# Save the combined text to a text file\n",
    "df['input_text'].to_csv(\"your_dataset.txt\", header=False, index=False)\n",
    "\n",
    "# Tokenize and process the dataset\n",
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"your_dataset.txt\",\n",
    "    block_size=128\n",
    ")\n",
    "\n",
    "# Create data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./FineTune\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Create Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90092b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e106d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "\n",
    "class ChatApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Chatbot Messenger\")\n",
    "        self.create_widgets()\n",
    "        self.model_name = \"./FineTune\"  # Replace with the path to your fine-tuned model directory\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.chat_history = scrolledtext.ScrolledText(self.root, wrap=tk.WORD, width=50, height=20)\n",
    "        self.chat_history.pack(pady=10)\n",
    "\n",
    "        self.entry = tk.Entry(self.root, width=40)\n",
    "        self.entry.pack(pady=10)\n",
    "        self.entry.bind(\"<Return>\", self.handle_user_input)\n",
    "\n",
    "        self.send_button = tk.Button(self.root, text=\"Send\", command=self.handle_user_input)\n",
    "        self.send_button.pack(pady=10)\n",
    "\n",
    "    def generate_response(self,prompt, max_length=100):\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        # Generate response\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        # Decode and return the generated text without repeating the user's input\n",
    "        response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        response = response.replace(prompt, \"\", 1).strip()  # Remove user's input from the response\n",
    "\n",
    "        response = response.split(\"?\", 1)[-1].strip()\n",
    "        return response\n",
    "\n",
    "    def handle_user_input(self, event=None):\n",
    "        user_input = self.entry.get()\n",
    "        if user_input:\n",
    "            response = self.generate_response(user_input)\n",
    "            self.update_chat_history(f\"You: {user_input}\\n\")\n",
    "            self.update_chat_history(f\"Bot: {response}\\n\", bot=True)\n",
    "            self.entry.delete(0, tk.END)\n",
    "\n",
    "    def update_chat_history(self, message, bot=False):\n",
    "        self.chat_history.config(state=tk.NORMAL)\n",
    "        if bot:\n",
    "            self.chat_history.tag_configure(\"bot\", justify=\"left\", foreground=\"blue\")\n",
    "            self.chat_history.insert(tk.END, message, \"bot\")\n",
    "        else:\n",
    "            self.chat_history.tag_configure(\"user\", justify=\"right\", foreground=\"green\")\n",
    "            self.chat_history.insert(tk.END, message, \"user\")\n",
    "        self.chat_history.see(tk.END)\n",
    "        self.chat_history.config(state=tk.DISABLED)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ChatApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b024a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
